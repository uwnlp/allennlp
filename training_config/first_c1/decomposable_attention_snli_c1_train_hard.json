{
    "dataset_reader": {
      "type": "snli",
      "token_indexers": {
        "tokens": {
          "type": "single_id",
          "lowercase_tokens": true
        },
        "token_characters": {
          "type": "characters",
          "character_tokenizer": {
            "byte_encoding": "utf-8",
            "start_tokens": [259],
            "end_tokens": [260]
          }
        }
      },
      "tokenizer": {
        "end_tokens": ["@@NULL@@"]
      }
    },
    "train_data_path": "/home/sg01/allennlp/data/snli_train_easy.json",
    "validation_data_path": "/home/sg01/allennlp/data/snli_dev_easy_subset.json",
    "model": {
      "type": "decomposable_attention_uw",
      "text_field_embedder": {
        "tokens": {
          "type": "embedding",
          "projection_dim": 200,
          "pretrained_file": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.300d.txt.gz",
          "embedding_dim": 300,
          "trainable": false,
        
        },
        "token_characters": {
          "type": "character_encoding",
          "embedding": {
            "num_embeddings": 262,
            "embedding_dim": 16
          },
          "encoder": {
            "type": "cnn",
            "embedding_dim": 16,
            "num_filters": 100,
            "ngram_filter_sizes": [3, 4, 5]
          },
          "dropout": 0.2
        }
      },
      "hypothesis_encoder": {
        "type": "lstm",
        "bidirectional": true,
        "input_size": 500,
        "hidden_size": 300,
        "num_layers": 3,
        "dropout": 0.2,
      },
      "attend_feedforward": {
        "input_dim": 600,
        "num_layers": 2,
        "hidden_dims": 200,
        "activations": "relu",
        "dropout": 0.2
      },
      "similarity_function": {"type": "dot_product"},
      "compare_feedforward": {
        "input_dim": 1200,
        "num_layers": 2,
        "hidden_dims": 200,
        "activations": "relu",
        "dropout": 0.2
      },
      "aggregate_feedforward": {
        "input_dim": 400,
        "num_layers": 2,
        "hidden_dims": [200, 3],
        "activations": ["relu", "linear"],
        "dropout": [0.2, 0.0]
      },
       "initializer": [
        [".*linear_layers.*weight", {"type": "xavier_normal"}],
        [".*token_embedder_tokens\._projection.*weight", {"type": "xavier_normal"}]
       ]
     },
    "iterator": {
      "type": "bucket",
      "sorting_keys": [["premise", "num_tokens"], ["hypothesis", "num_tokens"]],
      "batch_size": 64
    },
  
    "trainer": {
      "num_epochs": 140,
      "patience": 20,
      "cuda_device": 0,
      "grad_clipping": 5.0,
      "validation_metric": "+accuracy",
      "no_tqdm": true,
      "optimizer": {
        "type": "adagrad"
      }
    }
  }
  